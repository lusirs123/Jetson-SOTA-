import cv2
import time
import numpy as np
import onnxruntime as ort

# ================= é…ç½®åŒºåŸŸ =================
ONNX_MODEL_PATH = 'yolo26n.onnx'  # ç¡®ä¿ä½ å·²ç»ç”¨ yolo export å¯¼å‡ºäº†è¿™ä¸ªæ–‡ä»¶
VIDEO_PATH = 'test_video.mp4'      # å’Œä¹‹å‰æµ‹è¯•ç”¨åŒä¸€ä¸ªè§†é¢‘
OUTPUT_PATH = 'result_mac_onnx_cpu.mp4'
CONF_THRESHOLD = 0.25              # ç½®ä¿¡åº¦é˜ˆå€¼
INPUT_SIZE = 640                   # YOLO æ ‡å‡†è¾“å…¥å°ºå¯¸
# ===========================================

def preprocess(frame):
    """
    YOLO æ ‡å‡†é¢„å¤„ç†ï¼š
    1. Resize åˆ° 640x640
    2. å½’ä¸€åŒ– (0-255 -> 0-1)
    3. HWC -> BCHW (Batch, Channel, Height, Width)
    """
    height, width = frame.shape[:2]
    
    # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼Œç”¨äºåç»­ç”»æ¡†æ¢å¤åæ ‡
    scale_x = width / INPUT_SIZE
    scale_y = height / INPUT_SIZE
    
    img = cv2.resize(frame, (INPUT_SIZE, INPUT_SIZE))
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = img.astype(np.float32) / 255.0
    img = np.transpose(img, (2, 0, 1)) # HWC -> CHW
    img = np.expand_dims(img, axis=0)  # Add batch dimension -> BCHW
    return img, scale_x, scale_y

def postprocess(outputs, scale_x, scale_y, frame):
    """
    ç®€å•çš„åå¤„ç†ç”¨äºå¯è§†åŒ–ã€‚
    æ³¨æ„ï¼šä¸åŒç‰ˆæœ¬çš„ YOLO export æ ¼å¼å¯èƒ½ä¸åŒã€‚
    è¿™é‡Œå‡è®¾æ˜¯ [1, 84, 8400] æˆ–è€… [1, 6, 300] (End-to-End)ã€‚
    ä¸ºäº†ä¸å½±å“æµ‹é€Ÿï¼Œè¿™é‡Œåªåšæœ€ç®€å•çš„è§£ææ¼”ç¤ºã€‚
    """
    # è¿™é‡Œæˆ‘ä»¬ä¸»è¦å…³æ³¨æ¨ç†é€Ÿåº¦ï¼Œå¯è§†åŒ–åªç”»å‡ºå¤§æ¦‚å³å¯
    # å¦‚æœæ˜¯ NMS-Free çš„ End-to-End æ¨¡å‹ï¼Œè¾“å‡ºé€šå¸¸å¾ˆç®€å•
    pass 

def main():
    print(f"ğŸš€ Loading ONNX model {ONNX_MODEL_PATH} on CPU...")
    
    # 1. åŠ è½½ ONNX æ¨¡å‹ (å¼ºåˆ¶ä½¿ç”¨ CPU)
    try:
        session = ort.InferenceSession(ONNX_MODEL_PATH, providers=['CPUExecutionProvider'])
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œ yolo export model=yolov26n.pt format=onnx å¯¼å‡ºæ¨¡å‹")
        return

    # è·å–è¾“å…¥è¾“å‡ºèŠ‚ç‚¹åç§°
    input_name = session.get_inputs()[0].name
    output_name = session.get_outputs()[0].name

    cap = cv2.VideoCapture(VIDEO_PATH)
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘: {VIDEO_PATH}")
        return

    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps_video = cap.get(cv2.CAP_PROP_FPS)
    
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(OUTPUT_PATH, fourcc, fps_video, (width, height))

    print("ğŸ¥ å¼€å§‹ ONNX æ¨ç†... æŒ‰ 'q' é”®é€€å‡º")

    frame_count = 0
    instant_fps_list = []
    overall_start_time = time.time()

    while True:
        # å•å¸§è®¡æ—¶å¼€å§‹
        frame_start_time = time.time()
        
        ret, frame = cap.read()
        if not ret:
            break

        # --- 1. é¢„å¤„ç† ---
        input_tensor, scale_x, scale_y = preprocess(frame)

        # --- 2. æ¨ç† (æ ¸å¿ƒæµ‹é€Ÿéƒ¨åˆ†) ---
        outputs = session.run([output_name], {input_name: input_tensor})

        # --- 3. åå¤„ç† (ä¸ºäº†å…¬å¹³å¯¹æ¯”ï¼Œè¿™é‡Œå¯ä»¥ç®€åŒ–ï¼Œé‡ç‚¹æ˜¯ Session.run çš„è€—æ—¶) ---
        # å¦‚æœéœ€è¦ä¸¥æ ¼ç”»æ¡†ï¼Œéœ€è¦è§£æ outputs[0]
        # è¿™é‡Œä»…åšç®€å•çš„ FPS æ ‡è®°
        
        # --- 4. è®¡æ—¶ç»“æŸ ---
        frame_end_time = time.time()
        process_time = frame_end_time - frame_start_time
        
        instant_fps = 1.0 / process_time if process_time > 0 else 0.0
        instant_fps_list.append(instant_fps)
        frame_count += 1

        # æ˜¾ç¤º FPS
        display_fps = np.mean(instant_fps_list[-10:]) if len(instant_fps_list) > 10 else instant_fps
        cv2.rectangle(frame, (10, 10), (400, 60), (0, 0, 0), -1)
        cv2.putText(frame, 
                    f"ONNX CPU: {display_fps:.1f} FPS", 
                    (20, 50), 
                    cv2.FONT_HERSHEY_SIMPLEX, 
                    1.2, (0, 255, 0), 3) # ç»¿è‰²å­—ä½“åŒºåˆ†

        out.write(frame)
        cv2.imshow('YOLO26 Mac ONNX CPU', frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # æœ€ç»ˆç»Ÿè®¡
    overall_end_time = time.time()
    total_time = overall_end_time - overall_start_time
    avg_fps_all = frame_count / total_time if total_time > 0 else 0
    mean_instant_fps = np.mean(instant_fps_list) if instant_fps_list else 0

    cap.release()
    out.release()
    cv2.destroyAllWindows()

    # --- ä¸¥æ ¼å¯¹é½ä½ çš„æˆªå›¾æ ¼å¼ ---
    print("\n" + "="*30)
    print("3.3 Mac ONNX Runtime (CPU) æ¨ç†")  # å¸®ä½ æ‹Ÿå¥½äº†æ ‡é¢˜
    print(f"è¿è¡Œæ–‡ä»¶ benchmark_mac_onnx_cpu.py, å¾—åˆ°è¾“å‡º:")
    print(f"Total frames      : {frame_count}")
    print(f"Total time (s)    : {total_time:.1f}")
    print(f"Average FPS (all) : {avg_fps_all:.2f}")
    print(f"Mean instant FPS  : {mean_instant_fps:.2f}")
    print("="*30 + "\n")
    print(f"âœ… ç»“æœè§†é¢‘å·²ä¿å­˜è‡³: {OUTPUT_PATH}")

if __name__ == "__main__":
    main()



